{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cd20100c",
            "metadata": {},
            "source": [
                "# Documento Explicativo: Funcionamiento de Whisper en el Proyecto de Reconocimiento de Productos\n",
                "\n",
                "## Introducción\n",
                "Este proyecto utiliza la biblioteca **Whisper** de OpenAI para transcribir el audio de videos y detectar menciones de productos. Whisper es un modelo de inteligencia artificial basado en transformers que puede transcribir audio en múltiples idiomas con alta precisión. En este contexto, se integra en el servicio de video (`video_service.py`) para procesar archivos de video, extraer el audio y convertirlo en texto transcrito, que luego se anota con información de productos detectados visualmente.\n",
                "\n",
                "## Cómo Funciona Whisper en el Proyecto\n",
                "Whisper se utiliza en la función `process_video` del archivo `video_service.py`. Aquí se detalla el flujo:\n",
                "\n",
                "1. **Carga del Modelo**: \n",
                "    - Whisper se carga de manera lazy usando la función `get_whisper_model()`. Esto asegura que el modelo (versión \"base\") se cargue solo una vez y se reutilice en llamadas posteriores, optimizando el rendimiento.\n",
                "    - El modelo se configura para transcribir en español (`language=\"es\"`).\n",
                "\n",
                "2. **Transcripción del Audio**:\n",
                "    - Una vez cargado el modelo, se llama a `model.transcribe(video_path, language=\"es\")` para procesar el archivo de video.\n",
                "    - Whisper extrae automáticamente el audio del video y genera una transcripción segmentada, incluyendo timestamps de inicio y fin para cada segmento de texto.\n",
                "    - Los segmentos se almacenan en una lista de diccionarios con claves: `\"start\"`, `\"end\"` y `\"text\"`.\n",
                "\n",
                "3. **Integración con Detección Visual**:\n",
                "    - Paralelamente, el video se procesa para detectar productos usando SIFT (Scale-Invariant Feature Transform).\n",
                "    - Las detecciones visuales se agregan y se usan para anotar el texto transcrito, agregando etiquetas como `(SKU:product_id)` donde se detectan productos en el audio o en momentos superpuestos.\n",
                "\n",
                "4. **Anotación Final**:\n",
                "    - El texto transcrito se anota con SKUs basados en la detección visual y, opcionalmente, con un CSV de productos usando `annotate_text_with_csv`.\n",
                "    - Esto produce un texto final que combina la transcripción con información contextual de productos.\n",
                "\n",
                "### Ventajas de Whisper en Este Proyecto\n",
                "- **Precisión en Español**: Configurado para español, maneja acentos y jerga local.\n",
                "- **Eficiencia**: Modelo \"base\" es ligero y rápido para prototipos.\n",
                "- **Integración**: Funciona directamente con archivos de video sin necesidad de extraer audio manualmente.\n",
                "- **Segmentación**: Proporciona timestamps, permitiendo sincronización con detecciones visuales.\n",
                "\n",
                "### Limitaciones\n",
                "- Requiere GPU para rendimiento óptimo; en CPU puede ser lento para videos largos.\n",
                "- La transcripción puede tener errores en audio de baja calidad o con ruido de fondo.\n",
                "- No maneja idiomas mixtos automáticamente (fijado a español).\n",
                "\n",
                "## Pruebas Correspondientes\n",
                "Para probar el funcionamiento de Whisper, utilizamos el archivo `video_service.py` y un video de prueba `video_test.mp4`. Asegúrate de tener instaladas las dependencias: `openai-whisper`, `opencv-python`, y otros listados en el proyecto.\n",
                "\n",
                "### Código de Prueba\n",
                "Ejecuta el siguiente código en un entorno con acceso a los archivos. Asume que tienes un `sift_engine` configurado (por ejemplo, una instancia de una clase SIFT con base de datos de productos).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f7f2a30",
            "metadata": {
                "vscode": {
                    "languageId": "python"
                }
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Asegurarnos de que el directorio raíz del proyecto esté en el path\n",
                "sys.path.append(os.path.abspath('.'))\n",
                "\n",
                "from services.video_service import process_video\n",
                "from ml.models.sift_engine import get_sift_engine\n",
                "\n",
                "# 1. Inicializar el motor SIFT (Carga la base de datos de productos)\n",
                "try:\n",
                "    sift_engine = get_sift_engine()\n",
                "    print(\"Motor SIFT inicializado correctamente.\")\n",
                "except Exception as e:\n",
                "    print(f\"Error al inicializar SIFT: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "md1",
            "metadata": {},
            "source": [
                "### Ejecución del Procesamiento de Video\n",
                "A continuación, procesamos el video `video_test.mp4`. La función `process_video` realizará los pasos mencionados: detección visual, agregación, transcripción con Whisper y anotación final."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4c191076",
            "metadata": {
                "vscode": {
                    "languageId": "python"
                }
            },
            "outputs": [],
            "source": [
                "# 2. Definir la ruta del video de prueba\n",
                "video_path = 'video_test.mp4'\n",
                "\n",
                "if os.path.exists(video_path):\n",
                "    print(f\"Procesando video: {video_path}...\")\n",
                "    \n",
                "    # Llamada principal al servicio\n",
                "    # frame_every_seconds=1: Procesa un frame cada segundo para detección visual\n",
                "    try:\n",
                "        resultado = process_video(video_path, sift_engine, frame_every_seconds=1)\n",
                "        \n",
                "        print(\"\\n--- Resultado Final ---\")\n",
                "        print(resultado)\n",
                "    except Exception as e:\n",
                "        print(f\"Error durante el procesamiento: {e}\")\n",
                "else:\n",
                "    print(f\"El archivo {video_path} no existe. Por favor verifica la ruta.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "md2",
            "metadata": {},
            "source": [
                "### Análisis de Resultados\n",
                "El resultado de `process_video` es un string que contiene la transcripción del audio enriquecida.\n",
                "\n",
                "- **Detección Visual**: Si el sistema detectó productos visualmente (usando SIFT) durante el video, esos productos se habrán agregado al contexto del texto.\n",
                "- **Transcripción**: El texto base proviene de lo que Whisper escuchó en el video.\n",
                "- **Anotación**: Si hubo coincidencias entre lo dicho y lo visto, o menciones directas detectadas vía CSV, verás etiquetas como `(SKU:...)` insertadas en el texto.\n",
                "\n",
                "Este flujo permite que el chatbot tenga \"ojos y oídos\" sobre el contenido multimedia enviado por el usuario."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}